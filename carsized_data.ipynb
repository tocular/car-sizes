{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carsized Data\n",
    "\n",
    "This notebook scrapes car dimension data from carsized.com and exports it to CSV.\n",
    "\n",
    "**Data collected:**\n",
    "- Manufacturer, Car Name, Body Style\n",
    "- Production Start/End years\n",
    "- Dimensions: Length, Width, Width incl. mirrors, Height, Wheelbase, Ground Clearance\n",
    "- Cargo Volume (EU/US), Cargo Volume Max (EU/US)\n",
    "- Weight, Segment, Price (EU/US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install httpx selectolax pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tochi/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "from selectolax.parser import HTMLParser\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from typing import Optional\n",
    "import xml.etree.ElementTree as ET\n",
    "from dataclasses import dataclass, asdict\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CarData:\n",
    "    \"\"\"Data class for car specifications\"\"\"\n",
    "    url: str\n",
    "    manufacturer: Optional[str] = None\n",
    "    car_name: Optional[str] = None\n",
    "    body_style: Optional[str] = None\n",
    "    production_start: Optional[str] = None\n",
    "    production_end: Optional[str] = None\n",
    "    length: Optional[str] = None\n",
    "    width: Optional[str] = None\n",
    "    width_incl_mirrors: Optional[str] = None\n",
    "    height: Optional[str] = None\n",
    "    wheelbase: Optional[str] = None\n",
    "    ground_clearance: Optional[str] = None\n",
    "    cargo_volume_eu: Optional[str] = None\n",
    "    cargo_volume_us: Optional[str] = None\n",
    "    cargo_volume_max_eu: Optional[str] = None\n",
    "    cargo_volume_max_us: Optional[str] = None\n",
    "    weight: Optional[str] = None\n",
    "    segment: Optional[str] = None\n",
    "    price_eu: Optional[str] = None\n",
    "    price_us: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BASE_URL = \"https://www.carsized.com\"\n",
    "SITEMAP_INDEX_URL = f\"{BASE_URL}/sitemap.xml\"\n",
    "NUM_SITEMAPS = 55  # sitemap0.xml through sitemap54.xml\n",
    "\n",
    "# Rate limiting settings - be respectful to the server\n",
    "MIN_DELAY = 1.0  # Minimum seconds between requests\n",
    "MAX_DELAY = 2.0  # Maximum seconds between requests\n",
    "MAX_CONCURRENT_REQUESTS = 3  # Limit concurrent requests\n",
    "MAX_RETRIES = 3  # Max retries on failure\n",
    "RETRY_DELAY = 5  # Seconds to wait before retry\n",
    "\n",
    "# Request headers to mimic browser\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_urls_from_sitemap(sitemap_url: str, client: httpx.Client) -> list[str]:\n",
    "    \"\"\"Extract all car page URLs from a sitemap XML file.\n",
    "    Excludes URLs containing 'compare'.\n",
    "    \"\"\"\n",
    "    urls = []\n",
    "    try:\n",
    "        response = client.get(sitemap_url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        root = ET.fromstring(response.content)\n",
    "        namespace = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "        \n",
    "        for url_elem in root.findall('.//ns:url/ns:loc', namespace):\n",
    "            url = url_elem.text\n",
    "            if url and 'compare' not in url.lower():\n",
    "                urls.append(url)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_car_urls(client: httpx.Client) -> list[str]:\n",
    "    \"\"\"Collect all car URLs from all sitemaps.\"\"\"\n",
    "    all_urls = []\n",
    "    \n",
    "    for i in range(NUM_SITEMAPS):\n",
    "        sitemap_url = f\"{BASE_URL}/sitemap{i}.xml\"\n",
    "        urls = get_urls_from_sitemap(sitemap_url, client)\n",
    "        all_urls.extend(urls)\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    return all_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_dimension_value(text: str) -> Optional[str]:\n",
    "    \"\"\"Extract numeric value from dimension text (e.g., '493.5 cm' -> '493.5').\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    # Extract number (including decimals)\n",
    "    match = re.search(r'[\\d,.]+', text.replace(',', '.'))\n",
    "    return match.group() if match else None\n",
    "\n",
    "\n",
    "def extract_price_value(text: str) -> Optional[str]:\n",
    "    \"\"\"Extract numeric value from price text (e.g., '€ 87300' -> '87300').\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    # Remove currency symbols and extract number\n",
    "    cleaned = re.sub(r'[€$£,\\s]', '', text)\n",
    "    match = re.search(r'[\\d]+', cleaned)\n",
    "    return match.group() if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_label(texts: list) -> str:\n",
    "    \"\"\"Join label parts and remove superscript numbers.\"\"\"\n",
    "    label = ' '.join(t for t in texts[1:] if t).strip().lower()\n",
    "    # Remove trailing numbers (superscripts like Width2, Height1)\n",
    "    label = re.sub(r'[\\d,]+$', '', label).strip()\n",
    "    return label\n",
    "\n",
    "\n",
    "def parse_car_page(html: str, url: str) -> CarData:\n",
    "    \"\"\"Parse a car page HTML and extract all specifications.\"\"\"\n",
    "    tree = HTMLParser(html)\n",
    "    car = CarData(url=url)\n",
    "    \n",
    "    # Extract manufacturer\n",
    "    brand_elem = tree.css_first('[itemprop=\"brand\"]')\n",
    "    if brand_elem:\n",
    "        car.manufacturer = brand_elem.text(strip=True)\n",
    "    \n",
    "    # Extract car name/model - exclude generation code spans\n",
    "    model_elem = tree.css_first('[itemprop=\"model\"]')\n",
    "    if model_elem:\n",
    "        full_text = model_elem.text(strip=True)\n",
    "        # Remove generation code spans (e.g., \"4.1\", \"G05\")\n",
    "        gc_spans = model_elem.css('span.carmodelgc')\n",
    "        for gc in gc_spans:\n",
    "            gc_text = gc.text(strip=True)\n",
    "            full_text = full_text.replace(gc_text, '')\n",
    "        car.car_name = full_text.strip()\n",
    "    \n",
    "    # Extract body style\n",
    "    body_elem = tree.css_first('[itemprop=\"bodyType\"]')\n",
    "    if body_elem:\n",
    "        car.body_style = body_elem.text(strip=True)\n",
    "    \n",
    "    # Extract production years\n",
    "    date_elem = tree.css_first('[itemprop=\"vehicleModelDate\"]')\n",
    "    if date_elem:\n",
    "        date_text = date_elem.text(strip=True)\n",
    "        # Parse \"2023 - present\" or \"2018 - 2023\" format\n",
    "        if ' - ' in date_text:\n",
    "            parts = date_text.split(' - ')\n",
    "            car.production_start = parts[0].strip()\n",
    "            end = parts[1].strip().lower()\n",
    "            car.production_end = None if end == 'present' else parts[1].strip()\n",
    "        else:\n",
    "            car.production_start = date_text\n",
    "    \n",
    "    # Extract dimensions from the data matrix\n",
    "    content_rows = tree.css('.contentmargin')\n",
    "    \n",
    "    for row in content_rows:\n",
    "        title_divs = row.css('.dmatrixtitle, .dmatrixtitlesup')\n",
    "        texts = [d.text(strip=True) for d in title_divs]\n",
    "        \n",
    "        if len(texts) >= 2:\n",
    "            value_text = texts[0]\n",
    "            label = clean_label(texts)\n",
    "            \n",
    "            # Map labels to car attributes\n",
    "            if 'length' in label:\n",
    "                car.length = extract_dimension_value(value_text)\n",
    "            elif 'width incl' in label:\n",
    "                car.width_incl_mirrors = extract_dimension_value(value_text)\n",
    "            elif 'width' in label and 'incl' not in label:\n",
    "                car.width = extract_dimension_value(value_text)\n",
    "            elif 'height' in label:\n",
    "                car.height = extract_dimension_value(value_text)\n",
    "            elif 'wheelbase' in label:\n",
    "                car.wheelbase = extract_dimension_value(value_text)\n",
    "            elif 'ground clearance' in label:\n",
    "                car.ground_clearance = extract_dimension_value(value_text)\n",
    "            elif 'cargo volume max' in label and 'eu' in label:\n",
    "                car.cargo_volume_max_eu = extract_dimension_value(value_text)\n",
    "            elif 'cargo volume max' in label and 'us' in label:\n",
    "                car.cargo_volume_max_us = extract_dimension_value(value_text)\n",
    "            elif 'cargo volume' in label and 'eu' in label:\n",
    "                car.cargo_volume_eu = extract_dimension_value(value_text)\n",
    "            elif 'cargo volume' in label and 'us' in label:\n",
    "                car.cargo_volume_us = extract_dimension_value(value_text)\n",
    "            elif 'weight' in label:\n",
    "                car.weight = extract_dimension_value(value_text)\n",
    "            elif 'segment' in label:\n",
    "                car.segment = value_text\n",
    "            elif 'price eu' in label:\n",
    "                car.price_eu = extract_price_value(value_text)\n",
    "            elif 'price us' in label:\n",
    "                car.price_us = extract_price_value(value_text)\n",
    "    \n",
    "    return car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape_car_page(url: str, client: httpx.Client) -> Optional[CarData]:\n",
    "    \"\"\"Fetch and parse a single car page with retry logic.\"\"\"\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = client.get(url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return parse_car_page(response.text, url)\n",
    "            \n",
    "        except httpx.HTTPStatusError as e:\n",
    "            if e.response.status_code == 429:\n",
    "                time.sleep(RETRY_DELAY * (attempt + 1))\n",
    "            elif e.response.status_code == 403:\n",
    "                return None\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "        except Exception:\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                time.sleep(RETRY_DELAY)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape_all_cars(urls: list[str], checkpoint_every: int = 500) -> list[CarData]:\n",
    "    \"\"\"Scrape all car pages with rate limiting and checkpointing.\n",
    "    \n",
    "    Args:\n",
    "        urls: List of car page URLs to scrape\n",
    "        checkpoint_every: Save progress every N cars\n",
    "    \n",
    "    Returns:\n",
    "        List of CarData objects\n",
    "    \"\"\"\n",
    "    cars = []\n",
    "    \n",
    "    with httpx.Client(headers=HEADERS, follow_redirects=True) as client:\n",
    "        for i, url in enumerate(urls):\n",
    "            delay = random.uniform(MIN_DELAY, MAX_DELAY)\n",
    "            time.sleep(delay)\n",
    "            \n",
    "            car_data = scrape_car_page(url, client)\n",
    "            if car_data:\n",
    "                cars.append(car_data)\n",
    "            \n",
    "            if (i + 1) % checkpoint_every == 0:\n",
    "                checkpoint_df = pd.DataFrame([asdict(c) for c in cars])\n",
    "                checkpoint_df.to_csv(f'carsized_checkpoint_{i + 1}.csv', index=False)\n",
    "    \n",
    "    return cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def scrape_car_page_async(url: str, client: httpx.AsyncClient, semaphore: asyncio.Semaphore) -> Optional[CarData]:\n",
    "    \"\"\"Async version of car page scraper.\"\"\"\n",
    "    async with semaphore:\n",
    "        for attempt in range(MAX_RETRIES):\n",
    "            try:\n",
    "                await asyncio.sleep(random.uniform(MIN_DELAY, MAX_DELAY))\n",
    "                response = await client.get(url, timeout=30)\n",
    "                response.raise_for_status()\n",
    "                return parse_car_page(response.text, url)\n",
    "                \n",
    "            except httpx.HTTPStatusError as e:\n",
    "                if e.response.status_code == 429:\n",
    "                    await asyncio.sleep(RETRY_DELAY * (attempt + 1))\n",
    "                else:\n",
    "                    break\n",
    "            except Exception:\n",
    "                if attempt < MAX_RETRIES - 1:\n",
    "                    await asyncio.sleep(RETRY_DELAY)\n",
    "        return None\n",
    "\n",
    "\n",
    "async def scrape_all_cars_async(urls: list[str]) -> list[CarData]:\n",
    "    \"\"\"Async scraper with controlled concurrency.\"\"\"\n",
    "    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)\n",
    "    \n",
    "    async with httpx.AsyncClient(headers=HEADERS, follow_redirects=True) as client:\n",
    "        tasks = [scrape_car_page_async(url, client, semaphore) for url in urls]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    return [r for r in results if r is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Collect all URLs from sitemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2312"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with httpx.Client(headers=HEADERS, follow_redirects=True) as client:\n",
    "    all_urls = get_all_car_urls(client)\n",
    "\n",
    "len(all_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Test scraping on a few sample URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>car_name</th>\n",
       "      <th>body_style</th>\n",
       "      <th>production_start</th>\n",
       "      <th>production_end</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>width_incl_mirrors</th>\n",
       "      <th>height</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>ground_clearance</th>\n",
       "      <th>cargo_volume_eu</th>\n",
       "      <th>cargo_volume_us</th>\n",
       "      <th>cargo_volume_max_eu</th>\n",
       "      <th>cargo_volume_max_us</th>\n",
       "      <th>weight</th>\n",
       "      <th>segment</th>\n",
       "      <th>price_eu</th>\n",
       "      <th>price_us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.carsized.com/en/cars/abarth-500-20...</td>\n",
       "      <td>Abarth</td>\n",
       "      <td>50032</td>\n",
       "      <td>3-door Hatchback</td>\n",
       "      <td>2008</td>\n",
       "      <td>2016</td>\n",
       "      <td>365.7</td>\n",
       "      <td>162.7</td>\n",
       "      <td>189.3</td>\n",
       "      <td>148.5</td>\n",
       "      <td>230</td>\n",
       "      <td>10.4</td>\n",
       "      <td>185</td>\n",
       "      <td>None</td>\n",
       "      <td>610</td>\n",
       "      <td>None</td>\n",
       "      <td>1110</td>\n",
       "      <td>Standard</td>\n",
       "      <td>17850</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.carsized.com/en/cars/abarth-500-20...</td>\n",
       "      <td>Abarth</td>\n",
       "      <td>500</td>\n",
       "      <td>3-door Hatchback</td>\n",
       "      <td>2016</td>\n",
       "      <td>2022</td>\n",
       "      <td>366</td>\n",
       "      <td>162.7</td>\n",
       "      <td>189.3</td>\n",
       "      <td>148.5</td>\n",
       "      <td>230</td>\n",
       "      <td>10.4</td>\n",
       "      <td>185</td>\n",
       "      <td>None</td>\n",
       "      <td>610</td>\n",
       "      <td>None</td>\n",
       "      <td>1110</td>\n",
       "      <td>Standard</td>\n",
       "      <td>18490</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.carsized.com/en/cars/abarth-500-20...</td>\n",
       "      <td>Abarth</td>\n",
       "      <td>500 500e</td>\n",
       "      <td>Semi-cabriolet</td>\n",
       "      <td>2022</td>\n",
       "      <td>None</td>\n",
       "      <td>367.3</td>\n",
       "      <td>168.2</td>\n",
       "      <td>190</td>\n",
       "      <td>151.8</td>\n",
       "      <td>232.2</td>\n",
       "      <td>None</td>\n",
       "      <td>185</td>\n",
       "      <td>None</td>\n",
       "      <td>550</td>\n",
       "      <td>None</td>\n",
       "      <td>1435</td>\n",
       "      <td>Standard</td>\n",
       "      <td>40990</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.carsized.com/en/cars/abarth-punto-...</td>\n",
       "      <td>Abarth</td>\n",
       "      <td>Punto99</td>\n",
       "      <td>3-door Hatchback</td>\n",
       "      <td>2008</td>\n",
       "      <td>2010</td>\n",
       "      <td>404.1</td>\n",
       "      <td>172.6</td>\n",
       "      <td>None</td>\n",
       "      <td>149</td>\n",
       "      <td>251</td>\n",
       "      <td>None</td>\n",
       "      <td>275</td>\n",
       "      <td>None</td>\n",
       "      <td>1030</td>\n",
       "      <td>None</td>\n",
       "      <td>1260</td>\n",
       "      <td>Standard</td>\n",
       "      <td>18500</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.carsized.com/en/cars/acura-integra...</td>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Liftback</td>\n",
       "      <td>2022</td>\n",
       "      <td>None</td>\n",
       "      <td>471.9</td>\n",
       "      <td>182.9</td>\n",
       "      <td>None</td>\n",
       "      <td>141</td>\n",
       "      <td>273.6</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1399</td>\n",
       "      <td>Premium</td>\n",
       "      <td>None</td>\n",
       "      <td>31300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url manufacturer  car_name  \\\n",
       "0  https://www.carsized.com/en/cars/abarth-500-20...       Abarth     50032   \n",
       "1  https://www.carsized.com/en/cars/abarth-500-20...       Abarth       500   \n",
       "2  https://www.carsized.com/en/cars/abarth-500-20...       Abarth  500 500e   \n",
       "3  https://www.carsized.com/en/cars/abarth-punto-...       Abarth   Punto99   \n",
       "4  https://www.carsized.com/en/cars/acura-integra...        Acura   Integra   \n",
       "\n",
       "         body_style production_start production_end length  width  \\\n",
       "0  3-door Hatchback             2008           2016  365.7  162.7   \n",
       "1  3-door Hatchback             2016           2022    366  162.7   \n",
       "2    Semi-cabriolet             2022           None  367.3  168.2   \n",
       "3  3-door Hatchback             2008           2010  404.1  172.6   \n",
       "4          Liftback             2022           None  471.9  182.9   \n",
       "\n",
       "  width_incl_mirrors height wheelbase ground_clearance cargo_volume_eu  \\\n",
       "0              189.3  148.5       230             10.4             185   \n",
       "1              189.3  148.5       230             10.4             185   \n",
       "2                190  151.8     232.2             None             185   \n",
       "3               None    149       251             None             275   \n",
       "4               None    141     273.6               13            None   \n",
       "\n",
       "  cargo_volume_us cargo_volume_max_eu cargo_volume_max_us weight   segment  \\\n",
       "0            None                 610                None   1110  Standard   \n",
       "1            None                 610                None   1110  Standard   \n",
       "2            None                 550                None   1435  Standard   \n",
       "3            None                1030                None   1260  Standard   \n",
       "4            None                None                None   1399   Premium   \n",
       "\n",
       "  price_eu price_us  \n",
       "0    17850     None  \n",
       "1    18490     None  \n",
       "2    40990     None  \n",
       "3    18500     None  \n",
       "4     None    31300  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_urls = all_urls[:5] if all_urls else [\n",
    "    \"https://www.carsized.com/en/cars/bmw-x5-2023-suv/\",\n",
    "    \"https://www.carsized.com/en/cars/audi-a3-2020-5-door-hatchback/\",\n",
    "]\n",
    "\n",
    "sample_cars = scrape_all_cars(sample_urls)\n",
    "sample_df = pd.DataFrame([asdict(c) for c in sample_cars])\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Full scrape\n",
    "\n",
    "**Warning**: This will take a long time and make many requests to the server. Consider running in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Alternative: Run in batches\n",
    "BATCH_SIZE = 500\n",
    "START_BATCH = 0\n",
    "\n",
    "all_cars = []\n",
    "for batch_num in range(START_BATCH, len(all_urls) // BATCH_SIZE + 1):\n",
    "     start_idx = batch_num * BATCH_SIZE\n",
    "     end_idx = min((batch_num + 1) * BATCH_SIZE, len(all_urls))\n",
    "     batch_urls = all_urls[start_idx:end_idx]\n",
    "     \n",
    "     batch_cars = scrape_all_cars(batch_urls)\n",
    "     all_cars.extend(batch_cars)\n",
    "     \n",
    "     batch_df = pd.DataFrame([asdict(c) for c in batch_cars])\n",
    "     batch_df.to_csv(f'carsized_batch_{batch_num}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine batch files if you ran in batches\n",
    "import glob\n",
    "import os\n",
    "\n",
    "## Create tables directory if it doesn't exist\n",
    "os.makedirs('tables', exist_ok=True)\n",
    "\n",
    "batch_files = sorted(glob.glob('carsized_batch_*.csv'))\n",
    "if batch_files:\n",
    "    dfs = [pd.read_csv(f) for f in batch_files]\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    combined_df.to_csv('tables/carsized_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
